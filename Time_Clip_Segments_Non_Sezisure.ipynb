{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oshan35/Epileptic-Seizure-Prediction-with-EEG/blob/main/Time_Clip_Segments_Non_Sezisure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfXkue3Ast8V",
        "outputId": "8a4ed194-034b-4a1b-fb3f-0868a3f6ca6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48tjd1zms6OW",
        "outputId": "2bb1ece5-683a-4bf6-b77e-b10fdd41ef04"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.3)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from mne) (0.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.7.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "def create_log(name=\"preprocess-pipeline\"):\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Create a file handler\n",
        "    file_handler = logging.FileHandler(f\"{name}.log\")\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    file_handler.setFormatter(formatter)\n",
        "\n",
        "    # Add the file handler to the logger\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "    return logger"
      ],
      "metadata": {
        "id": "BDlqwJm6jLln"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Extraction"
      ],
      "metadata": {
        "id": "yhZVdZvJrsEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wavelet coefficents"
      ],
      "metadata": {
        "id": "Za5K6o6rrvoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuer_log = create_log(\"featuer-extraction\")"
      ],
      "metadata": {
        "id": "A9tXD_Pjf6Uc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from scipy.signal import welch\n",
        "from pywt import wavedec\n",
        "\n",
        "def compute_energy(coefficients):\n",
        "    if isinstance(coefficients, np.ndarray):\n",
        "        return np.sum(np.square(np.abs(coefficients))) / len(coefficients)\n",
        "    elif np.isscalar(coefficients):\n",
        "        return np.square(np.abs(coefficients))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported type for coefficients\")\n",
        "\n",
        "def compute_total_energy(approximation_coefficients, detail_coefficients):\n",
        "    total_energy = 0\n",
        "    total_energy += compute_energy(approximation_coefficients)\n",
        "    for detail_coefficient in detail_coefficients:\n",
        "        total_energy += compute_energy(detail_coefficient)\n",
        "    return total_energy\n",
        "\n",
        "def calculate_D_Energy(detail_coefficients):\n",
        "    total_energy = 0\n",
        "    for detail_coefficient in detail_coefficients:\n",
        "        total_energy += compute_energy(detail_coefficient)\n",
        "    return total_energy\n",
        "\n",
        "\n",
        "def compute_mean(coefficients):\n",
        "    return np.mean(coefficients)\n",
        "\n",
        "def compute_std(coefficients):\n",
        "    return np.std(coefficients)\n",
        "\n",
        "def calculate_D_mean(coeffs):\n",
        "    valid_indices = [i for i in range(1, min(6, len(coeffs)))]\n",
        "    return np.mean([np.mean(coeffs[i]) for i in valid_indices])\n",
        "\n",
        "\n",
        "def calculate_A_mean(coeffs):\n",
        "    return compute_mean(coeffs[0])\n",
        "\n",
        "def calculate_D_std(coeffs):\n",
        "    return np.mean([compute_std(coeffs[i]) for i in range(min(6, len(coeffs)))])\n",
        "\n",
        "def calculate_A_std(coeffs):\n",
        "    return compute_std(coeffs[0])\n",
        "\n",
        "\n",
        "def wavelet_feature_extraction(data, type_wav, sampling_frequency, nperseg):\n",
        "    coefficients = wavedec(data, type_wav, level=5)\n",
        "\n",
        "    total_energy = compute_total_energy(coefficients[0], coefficients[1:])\n",
        "    cD_Energy=calculate_D_Energy(coefficients[1:])\n",
        "    cA_Energy=compute_energy(coefficients[0])\n",
        "    cD_mean = calculate_D_mean(coefficients[1:])\n",
        "    cA_mean = calculate_A_mean(coefficients[0])\n",
        "    cD_std = calculate_D_std(coefficients[1:])\n",
        "    cA_std = calculate_A_std(coefficients[0])\n",
        "\n",
        "    return [\n",
        "        total_energy,\n",
        "        cD_Energy,\n",
        "        cA_Energy,\n",
        "        cD_mean,\n",
        "        cA_mean,\n",
        "        cD_std,\n",
        "        cA_std,\n",
        "    ]\n",
        "\n",
        "  #test"
      ],
      "metadata": {
        "id": "USYpboB4rzL9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Frequency Domain coefficents"
      ],
      "metadata": {
        "id": "2NkvrDRAr5Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.signal\n",
        "import numpy as np\n",
        "\n",
        "def get_median_frequency(psd):\n",
        "    median_frequency = np.median(psd)\n",
        "\n",
        "    return median_frequency\n",
        "\n",
        "def get_edge_frequency(psd):\n",
        "    edge_frequency = np.where(psd >= psd.max() / 2)[0][0]\n",
        "\n",
        "    return edge_frequency\n",
        "\n",
        "def compute_power_spectral_density(data, sampling_frequency, nperseg=256):\n",
        "    _, psd = scipy.signal.welch(data, fs=sampling_frequency, nperseg=nperseg)\n",
        "    return psd\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = scipy.signal.butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = scipy.signal.lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "def compute_band_power(psd_result, freq_band_indices, fs, nperseg):\n",
        "    freq_band_power = np.sum(psd_result[freq_band_indices]) * fs / nperseg\n",
        "    return freq_band_power\n",
        "\n",
        "def compute_spectral_entropy(psd):\n",
        "    normalized_psd = psd / np.sum(psd)  # Normalize to obtain probabilities\n",
        "    spectral_entropy = -np.sum(normalized_psd * np.log2(normalized_psd))\n",
        "    return spectral_entropy\n",
        "\n",
        "def extract_frequency_domain_features(signal, sampling_frequency, nperseg=256):\n",
        "    # Apply Butterworth bandpass filters\n",
        "    delta_band_signal = butter_bandpass_filter(signal, 0.5, 4, sampling_frequency)\n",
        "    theta_band_signal = butter_bandpass_filter(signal, 4, 8, sampling_frequency)\n",
        "    alpha_band_signal = butter_bandpass_filter(signal, 8, 13, sampling_frequency)\n",
        "    beta_band_signal = butter_bandpass_filter(signal, 13, 30, sampling_frequency)\n",
        "    gamma_band_signal = butter_bandpass_filter(signal, 30, 40, sampling_frequency)\n",
        "\n",
        "    # Compute Power Spectral Density for each band\n",
        "    delta_psd = compute_power_spectral_density(delta_band_signal, sampling_frequency, nperseg=nperseg)\n",
        "    theta_psd = compute_power_spectral_density(theta_band_signal, sampling_frequency, nperseg=nperseg)\n",
        "    alpha_psd = compute_power_spectral_density(alpha_band_signal, sampling_frequency, nperseg=nperseg)\n",
        "    beta_psd = compute_power_spectral_density(beta_band_signal, sampling_frequency, nperseg=nperseg)\n",
        "    gamma_psd = compute_power_spectral_density(gamma_band_signal, sampling_frequency, nperseg=nperseg)\n",
        "\n",
        "    # Compute Band Power for each frequency band\n",
        "    freq_band_indices = [range(int(nperseg * band[0] / sampling_frequency), int(nperseg * band[1] / sampling_frequency)) for band in [(0.5, 4), (4, 8), (8, 13), (13, 30), (30, 40)]]\n",
        "\n",
        "    delta_band_power = compute_band_power(delta_psd, freq_band_indices[0], sampling_frequency, nperseg)\n",
        "    theta_band_power = compute_band_power(theta_psd, freq_band_indices[1], sampling_frequency, nperseg)\n",
        "    alpha_band_power = compute_band_power(alpha_psd, freq_band_indices[2], sampling_frequency, nperseg)\n",
        "    beta_band_power = compute_band_power(beta_psd, freq_band_indices[3], sampling_frequency, nperseg)\n",
        "    gamma_band_power = compute_band_power(gamma_psd, freq_band_indices[4], sampling_frequency, nperseg)\n",
        "\n",
        "    spectral_entropy_result = compute_spectral_entropy(np.concatenate([delta_psd, theta_psd, alpha_psd, beta_psd, gamma_psd]))\n",
        "    # Compute the power spectral density (PSD)\n",
        "    psd, _ = scipy.signal.welch(signal, fs=sampling_frequency, nperseg=nperseg)\n",
        "\n",
        "    return [\n",
        "        delta_band_power,\n",
        "        theta_band_power,\n",
        "        alpha_band_power,\n",
        "        beta_band_power,\n",
        "        gamma_band_power,\n",
        "        spectral_entropy_result,\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "nr1UFcvMruIA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Time Domain coefficents"
      ],
      "metadata": {
        "id": "rezQXOYbsBCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.fft import fft\n",
        "import pywt\n",
        "import os\n",
        "from scipy.stats import entropy, skew, kurtosis\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = scipy.signal.butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "def compute_standard_deviation(data):\n",
        "    return np.std(data)\n",
        "\n",
        "def compute_skewness(data):\n",
        "    return skew(data)\n",
        "\n",
        "def compute_kurtosis(data):\n",
        "    return kurtosis(data)\n",
        "\n",
        "def compute_median(data):\n",
        "    return np.median(data)\n",
        "\n",
        "def compute_band_power_time(data, sampling_frequency, nperseg):\n",
        "    _, power_density = welch(data, fs=sampling_frequency, nperseg=nperseg)\n",
        "    return np.mean(power_density)\n",
        "def peak_to_peak_voltage(data):\n",
        "    return np.ptp(data)\n",
        "\n",
        "def total_signal_area(data):\n",
        "    return np.sum(np.abs(data))\n",
        "\n",
        "def decorrelation_time(data):\n",
        "    autocorrelation = np.correlate(data, data, mode='full')\n",
        "    zero_crossings = np.where(np.diff(np.sign(autocorrelation)))[0]\n",
        "\n",
        "    if len(zero_crossings) > 0:\n",
        "        first_zero_crossing = zero_crossings[0]\n",
        "        time_points = np.arange(len(autocorrelation))\n",
        "        decorrelation_time = time_points[first_zero_crossing]\n",
        "        return decorrelation_time\n",
        "    else:\n",
        "        return -1\n",
        "def extract_time_domain_features(raw_data,sampling_frequency, nperseg):\n",
        "    data=butter_bandpass_filter(raw_data, 0.5, 40, sampling_frequency)\n",
        "    features = [\n",
        "        compute_standard_deviation(data),\n",
        "        compute_skewness(data),\n",
        "        compute_kurtosis(data),\n",
        "        compute_median(data),\n",
        "        compute_band_power_time(data, sampling_frequency, nperseg),\n",
        "        peak_to_peak_voltage(data),\n",
        "        total_signal_area(data),\n",
        "        decorrelation_time(data)\n",
        "    ]\n",
        "    return features"
      ],
      "metadata": {
        "id": "LrNgQFT2sDby"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction"
      ],
      "metadata": {
        "id": "-Y6fZKqPsIzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "from scipy.fft import fft\n",
        "import pywt\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def calculate_mean(segments,feature_names):\n",
        "    num_segments,num_channels, num_features = np.array(segments).shape\n",
        "    mean_features=[]\n",
        "    df = pd.DataFrame(columns=feature_names)\n",
        "\n",
        "    for channel in range(num_channels):\n",
        "      feature_array=[]\n",
        "      feature_array_total=[]\n",
        "      for segment in range(num_segments):\n",
        "        feature_array= segments[segment][channel]\n",
        "        print(feature_array)\n",
        "        feature_array_total.append(feature_array)\n",
        "      #mean_features.append(np.mean(feature_array_total))\n",
        "      a_series = pd.Series(np.mean(feature_array_total), index=feature_names)\n",
        "      df = df.append(a_series, ignore_index=True)\n",
        "\n",
        "\n",
        "    return (df)\n",
        "\n",
        "def extract_features(segment, seizure):\n",
        "    num_channels, num_time_points = segment.shape\n",
        "    all_features = []\n",
        "\n",
        "    for channel_index, channel_data in enumerate(segment):\n",
        "        extracted_features = []\n",
        "        wavelet_name = 'db4'\n",
        "        extracted_features.extend(wavelet_feature_extraction(channel_data, wavelet_name, 256, 256))\n",
        "        extracted_features.extend(extract_time_domain_features(channel_data, 256, 256))\n",
        "        extracted_features.extend(extract_frequency_domain_features(channel_data, 256))\n",
        "        if seizure:\n",
        "          extracted_features.extend([channel_index, 1])\n",
        "        else:\n",
        "          extracted_features.extend([channel_index, 0])\n",
        "\n",
        "        all_features.append(extracted_features)\n",
        "\n",
        "    return np.array(all_features)\n",
        "\n",
        "def extract_features_without_segments(data, time_window_duration = 60, seizure = False):\n",
        "    num_channels, num_data_points = data.shape\n",
        "    data_per_segment = time_window_duration * 256\n",
        "    feature_names = [  'total_energy', 'cD_Energy', 'cA_Energy', 'cD_mean', 'cA_mean', 'cD_std', 'cA_std',  'std_deviation', 'skewness', 'kurtosis', 'median', 'band_power', 'peak_to_peak_voltage',  'total_signal_area', 'decorrelation_time', 'delta_power', 'theta_power', 'alpha_power',  'beta_power', 'gamma_power', 'spectral_entropy','seizure']\n",
        "    num_segments = num_data_points // data_per_segment\n",
        "    all_features = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        print('segment', i)\n",
        "        features = extract_features(data[:, i * data_per_segment: (i + 1) * data_per_segment],seizure)\n",
        "        all_features.append(features)\n",
        "    featuer_log.info(f\"äll featuers before averaging: {np.array(all_features).shape}\")\n",
        "\n",
        "    featuer_log.info(f\"äll featuers after averaging: {np.array(calculate_mean(all_features)).shape}\")\n",
        "    return calculate_mean(all_features,feature_names)\n",
        "\n"
      ],
      "metadata": {
        "id": "3ojz6ayXsLK4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_and_process_files(folder_path, time_window_duration = 60):\n",
        "#     file_list = [f for f in os.listdir(folder_path) if f.endswith('.npy')]\n",
        "\n",
        "#     df=pd.DataFrame(columns=feature_names)\n",
        "\n",
        "#     for file_name in file_list:\n",
        "#         file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "#         data = np.load(file_path)\n",
        "#         features = extract_features_without_segments(data, time_window_duration,feature_names)\n",
        "#         df = pd.concat([df, features], ignore_index=True)\n",
        "\n",
        "#         print('file: ',file_name)\n",
        "#         del data\n",
        "\n",
        "#     return df"
      ],
      "metadata": {
        "id": "Qimht3wjsPgL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "7Uvksy_WsUQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_log = create_log()"
      ],
      "metadata": {
        "id": "mOIxAEZ4g6k-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class EEGData:\n",
        "    def __init__(self, file_name, file_start_time, file_end_time, num_seizures, seizure_times=[]):\n",
        "        self.file_name = file_name\n",
        "        self.file_start_time = file_start_time\n",
        "        self.file_end_time = file_end_time\n",
        "        self.num_seizures = num_seizures\n",
        "        self.seizure_times = seizure_times\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"EEGData(File Name: {self.file_name}, \"\n",
        "                f\"File Start Time: {self.file_start_time}, \"\n",
        "                f\"File End Time: {self.file_end_time}, \"\n",
        "                f\"Number of Seizures: {self.num_seizures}, \"\n",
        "                f\"Number of Seizures: {self.seizure_times})\")"
      ],
      "metadata": {
        "id": "zRQ-b5X9t2fI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_eeg_data(file_path):\n",
        "    eeg_data_objects = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    current_file_data = {}\n",
        "    num_seizures = 0\n",
        "    line_index = 0\n",
        "    while line_index<len(lines):\n",
        "      line = lines[line_index]\n",
        "      if line.startswith('File Name:'):\n",
        "          if current_file_data:\n",
        "              # Create EEGData object from the current_file_data\n",
        "              eeg_data = EEGData(**current_file_data)\n",
        "              eeg_data_objects.append(eeg_data)\n",
        "\n",
        "              current_file_data = {}\n",
        "          current_file_data['file_name'] = line.split(': ')[1].strip()\n",
        "      elif line.startswith('File Start Time:'):\n",
        "          current_file_data['file_start_time'] = line.split(': ')[1].strip()\n",
        "      elif line.startswith('File End Time:'):\n",
        "          current_file_data['file_end_time'] = line.split(': ')[1].strip()\n",
        "      elif line.startswith('Number of Seizures in File:'):\n",
        "          current_file_data['num_seizures'] = int(line.split(': ')[1].strip())\n",
        "          num_seizures = current_file_data['num_seizures']\n",
        "\n",
        "          seizure_times = []\n",
        "\n",
        "          if num_seizures > 1:\n",
        "\n",
        "            for x in range(num_seizures):\n",
        "              line_index += 1\n",
        "              start = int(lines[line_index].split(\": \")[1].strip().split(\" \")[0].strip())\n",
        "              line_index += 1\n",
        "              end = int(lines[line_index].split(\": \")[1].strip().split(\" \")[0].strip())\n",
        "              seizure = (start,end)\n",
        "              seizure_times.append(seizure)\n",
        "\n",
        "          elif num_seizures  == 1:\n",
        "            line_index += 1\n",
        "            start = int(lines[line_index].split(\": \")[1].split(\" \")[0].strip())\n",
        "            line_index += 1\n",
        "            end = int(lines[line_index].split(\": \")[1].split(\" \")[0].strip())\n",
        "            seizure_times.append((start,end))\n",
        "\n",
        "          current_file_data['seizure_times'] = seizure_times\n",
        "\n",
        "          if 'file_name' in current_file_data:\n",
        "              eeg_data = EEGData(**current_file_data)\n",
        "              eeg_data_objects.append(eeg_data)\n",
        "              current_file_data = {}\n",
        "      line_index += 1\n",
        "    return eeg_data_objects\n"
      ],
      "metadata": {
        "id": "lwTzw7Y2H1MN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import mne\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def load_data_from_file(patient_id,file_name):\n",
        "  file = f\"/content/drive/MyDrive/EEG-Projects/CHB-MIT/{patient_id}/{file_name}\"\n",
        "  data = mne.io.read_raw_edf(file)\n",
        "  preprocessing_log.info(f\"loaded EDF file at {file_name} with patient id : {patient_id}\")\n",
        "  return data"
      ],
      "metadata": {
        "id": "6BRBcnlcunpg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def clean_channel_data(data_file):\n",
        "  data = data_file.get_data()\n",
        "  preprocessing_log.info(f\"data shape before cleaning: {data.shape}\")\n",
        "\n",
        "  modified_data = []\n",
        "  channel_num, data_num = data.shape\n",
        "  if channel_num > 23:\n",
        "    additional_channel = True\n",
        "    for channel_index in range(len(data)):\n",
        "      element = data[channel_index][random.randint(0,data_num-1)]\n",
        "\n",
        "      if element != -1e-06:\n",
        "        modified_data.append(data[channel_index])\n",
        "      else:\n",
        "        preprocessing_log.info(f\"removed channel index {channel_index}\")\n",
        "\n",
        "    if len(modified_data) > 23:\n",
        "      modified_data.pop(-1)\n",
        "      preprocessing_log.info(f\"removed ECG channel\")\n",
        "\n",
        "    new_data = np.array(modified_data)\n",
        "    preprocessing_log.info(f\"data shape changed from {data.shape} => {new_data.shape}\")\n",
        "    del modified_data,data\n",
        "    gc.collect()\n",
        "    return new_data\n",
        "\n",
        "  preprocessing_log.info(\"data is clean\")\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "NTNOPXeJiGez"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_non_sezizer_segments(patient_id,eeg_data_objects, segment_length = 600, time_gap =300):\n",
        "  count = 0\n",
        "  df=pd.DataFrame()\n",
        "\n",
        "  for i in range(len(eeg_data_objects)):\n",
        "    if (int(eeg_data_objects[i].num_seizures) == 0) and i-4 >= 0 and i+3 < len(eeg_data_objects):\n",
        "      preprocessing_log.info(f\"[+] non-seizure: {eeg_data_objects[i]}\")\n",
        "      flag = True\n",
        "      index = i-1\n",
        "      for j in range(4):\n",
        "        if eeg_data_objects[index].num_seizures != 0:\n",
        "          flag = False\n",
        "        index-=1\n",
        "      index = i\n",
        "      for k in range(3):\n",
        "        if eeg_data_objects[index].num_seizures != 0:\n",
        "          flag = False\n",
        "        index+=1\n",
        "\n",
        "      if flag:\n",
        "        preprocessing_log.info(f\"{eeg_data_objects[i]}, {eeg_data_objects[i-1]}\")\n",
        "        # print(eeg_data_objects[i],eeg_data_objects[i-1])\n",
        "        obj1 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i].file_name))\n",
        "\n",
        "        obj2 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i-1].file_name))\n",
        "\n",
        "        f1_no = eeg_data_objects[i].file_name.split('_')[1].split('.')[0]\n",
        "        f2_no = eeg_data_objects[i-1].file_name.split('_')[1].split('.')[0]\n",
        "\n",
        "        conect_data = np.concatenate((obj1, obj2), axis=1)[:segment_length*256]\n",
        "        preprocessing_log.info(f\"conect data shape non-seizure: {conect_data.shape}\")\n",
        "        preprocessing_log.info(f\"time range non-sezuer: {segment_length/3600}\")\n",
        "\n",
        "\n",
        "        extracted_features = extract_features_without_segments(conect_data)\n",
        "        df = pd.concat([df, extracted_features], ignore_index=True)\n",
        "\n",
        "        preprocessing_log.info(f\"extracted featuer shape: {extracted_featuers.shape}\")\n",
        "        np.save(f\"/content/drive/MyDrive/EEG-Projects/CHB-MIT-Extracted-Featuers/non-seizuer-cases/{patient_id}-{f1_no}-{f2_no}.npy\",extracted_featuers)\n",
        "\n",
        "\n",
        "\n",
        "        del obj1\n",
        "        del obj2\n",
        "        del conect_data\n",
        "        gc.collect()\n",
        "    elif (int(eeg_data_objects[i].num_seizures) > 0) and (i-2 >= 0):\n",
        "      preprocessing_log.info(f\"[+] seizure: {eeg_data_objects[i]}\")\n",
        "      f1_no = eeg_data_objects[i].file_name.split('_')[1].split('.')[0]\n",
        "      f2_no = eeg_data_objects[i-1].file_name.split('_')[1].split('.')[0]\n",
        "      flag = True\n",
        "\n",
        "\n",
        "      obj1 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i].file_name))\n",
        "      obj2 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i-1].file_name))\n",
        "      obj3 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i-2].file_name))\n",
        "      time_correction = len(obj2[0])/256 + len(obj3[0])/256\n",
        "      shape_flag = False\n",
        "\n",
        "      if obj1.shape[0] == obj2.shape[0] == obj3.shape[0]:\n",
        "\n",
        "        shape_flag = True\n",
        "\n",
        "      obj4 = None\n",
        "      if i-3 >= 0:\n",
        "        obj4 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i-3].file_name))\n",
        "        if obj1.shape[0] != obj4.shape[0] and shape_flag == True:\n",
        "          shape_flag = False\n",
        "\n",
        "        time_correction += len(obj4[0])/256\n",
        "\n",
        "      preprocessing_log.info(f\"data shapes: {obj1.shape} {obj2.shape} {obj3.shape}\")\n",
        "\n",
        "      if shape_flag == False:\n",
        "        preprocessing_log.info(\"Shapes doesn't match!\")\n",
        "        continue\n",
        "\n",
        "      preprocessing_log.info(f\"time correction: {time_correction}\")\n",
        "\n",
        "      timeline = []\n",
        "      if np.all(obj4 != None):\n",
        "        timeline = np.concatenate((obj4,obj3,obj2,obj1),axis=1)\n",
        "      else:\n",
        "        timeline = np.concatenate((obj3,obj2,obj1),axis=1)\n",
        "\n",
        "      preprocessing_log.info(timeline.shape)\n",
        "\n",
        "      s_count = 0\n",
        "      for s in eeg_data_objects[i].seizure_times:\n",
        "        seizure_data = []\n",
        "\n",
        "        start_time = s[0] + time_correction\n",
        "        end_time = s[1] + time_correction\n",
        "        preprocessing_log.info(f\"capture margin: {start_time} - {end_time}\")\n",
        "\n",
        "        end_margin = start_time - time_gap\n",
        "        start_margin = end_margin - segment_length\n",
        "\n",
        "        start_data_index = int(start_margin * 256)\n",
        "        end_data_index = int(end_margin * 256)\n",
        "        n_channels = timeline.shape[0]\n",
        "        for x in range(n_channels):\n",
        "\n",
        "          channel_data = timeline[x][start_data_index:end_data_index]\n",
        "          seizure_data.append(channel_data)\n",
        "        np_seizure = np.array(seizure_data,dtype=np.float32)\n",
        "\n",
        "        preprocessing_log.info(f\"pre-ictal data shape: {np_seizure.shape}\")\n",
        "        extracted_featuers = extract_features_without_segments(np_seizure, seizure=True)\n",
        "        df = pd.concat([df, extracted_features], ignore_index=True)\n",
        "\n",
        "\n",
        "       # np.save(f\"/content/drive/MyDrive/EEG-Projects/CHB-MIT-Extracted-Featuers/seizuer-cases/{patient_id}-{f1_no}-{f2_no}.npy\",extracted_featuers)\n",
        "\n",
        "\n",
        "        preprocessing_log.info(f\"extracted featuer shape: {np.array(extracted_featuers).shape}\")\n",
        "        s_count+=1\n",
        "      preprocessing_log.info(f\"time range sezuer: {segment_length/3600}\")\n",
        "      preprocessing_log.info(f\"number of sezuers: {s_count}\")\n",
        "\n",
        "      preprocessing_log.info(f\"data length: {len(seizure_data)}\")\n",
        "      del obj1,obj2,obj3,obj4,seizure_data\n",
        "      gc.collect()\n",
        "    count+=1\n",
        "  return df"
      ],
      "metadata": {
        "id": "9p96sIMp2qV3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_two_hour_segments(patient_id):\n",
        "  eeg_data_objects = parse_eeg_data(f'/content/drive/MyDrive/EEG-Projects/CHB-MIT/{patient_id}/{patient_id}-summary.txt')\n",
        "  df=create_non_sezizer_segments(patient_id,eeg_data_objects)\n",
        "  del eeg_data_objects\n",
        "  gc.collect\n",
        "  return df"
      ],
      "metadata": {
        "id": "LhXZmqJQB06g"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gowpbEqPR3TB",
        "outputId": "81ab05e8-b17e-4272-d67c-0547eba580c6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm \"preprocess-pipeline.log\"\n",
        "# create_log()"
      ],
      "metadata": {
        "id": "pyiIfNtZTuie"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# patient_id = \"chb13\"\n",
        "# load_two_hour_segments(patient_id)"
      ],
      "metadata": {
        "id": "GuRC2ur9RxWj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = [  'total_energy', 'cD_Energy', 'cA_Energy', 'cD_mean', 'cA_mean', 'cD_std', 'cA_std',  'std_deviation', 'skewness', 'kurtosis', 'median', 'band_power', 'peak_to_peak_voltage',  'total_signal_area', 'decorrelation_time', 'delta_power', 'theta_power', 'alpha_power',  'beta_power', 'gamma_power', 'spectral_entropy','seizure']\n",
        "df=pd.DataFrame(columns=feature_names)\n",
        "\n",
        "for i in range(2):\n",
        "  patient_id = f\"chb{i+1:02d}\"\n",
        "  patient_df=load_two_hour_segments(patient_id)\n",
        "  df = pd.concat([df, patient_df], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "ybTIc8q4BOU7",
        "outputId": "6a956ace-6d7e-41eb-ee2e-fff6d2c00a90"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-5bca29b0fdf9>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mpatient_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"chb{i+1:02d}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mpatient_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_two_hour_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-d99158018960>\u001b[0m in \u001b[0;36mload_two_hour_segments\u001b[0;34m(patient_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_two_hour_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0meeg_data_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_eeg_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/EEG-Projects/CHB-MIT/{patient_id}/{patient_id}-summary.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_non_sezizer_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meeg_data_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0meeg_data_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-0f6e28b2ab46>\u001b[0m in \u001b[0;36mparse_eeg_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0meeg_data_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcurrent_file_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/EEG-Projects/CHB-MIT/chb01/chb01-summary.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "k3ZQhppJv6v9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}