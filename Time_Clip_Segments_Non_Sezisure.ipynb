{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oshan35/Epileptic-Seizure-Prediction-with-EEG/blob/main/Time_Clip_Segments_Non_Sezisure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfXkue3Ast8V",
        "outputId": "38df8e44-54e8-4611-9796-54159b544cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48tjd1zms6OW",
        "outputId": "7fdc135f-6e34-4d37-9177-5c5d4454a932"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.3)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from mne) (0.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.7.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "def create_log(name=\"preprocess-pipeline\"):\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Create a file handler\n",
        "    file_handler = logging.FileHandler(f\"{name}.log\")\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    file_handler.setFormatter(formatter)\n",
        "\n",
        "    # Add the file handler to the logger\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "    return logger"
      ],
      "metadata": {
        "id": "BDlqwJm6jLln"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Extraction"
      ],
      "metadata": {
        "id": "yhZVdZvJrsEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wavelet coefficents"
      ],
      "metadata": {
        "id": "Za5K6o6rrvoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuer_log = create_log(\"featuer-extraction\")"
      ],
      "metadata": {
        "id": "A9tXD_Pjf6Uc"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from scipy.signal import welch\n",
        "from pywt import wavedec\n",
        "\n",
        "def compute_energy(coefficients):\n",
        "    if isinstance(coefficients, np.ndarray):\n",
        "        return np.sum(np.square(np.abs(coefficients))) / len(coefficients)\n",
        "    elif np.isscalar(coefficients):\n",
        "        return np.square(np.abs(coefficients))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported type for coefficients\")\n",
        "\n",
        "def compute_total_energy(approximation_coefficients, detail_coefficients):\n",
        "    total_energy = 0\n",
        "    total_energy += compute_energy(approximation_coefficients)\n",
        "    for detail_coefficient in detail_coefficients:\n",
        "        total_energy += compute_energy(detail_coefficient)\n",
        "    return total_energy\n",
        "\n",
        "def calculate_D_Energy(detail_coefficients):\n",
        "    total_energy = 0\n",
        "    for detail_coefficient in detail_coefficients:\n",
        "        total_energy += compute_energy(detail_coefficient)\n",
        "    return total_energy\n",
        "\n",
        "\n",
        "def compute_mean(coefficients):\n",
        "    return np.mean(coefficients)\n",
        "\n",
        "def compute_std(coefficients):\n",
        "    return np.std(coefficients)\n",
        "\n",
        "def calculate_D_mean(coeffs):\n",
        "    valid_indices = [i for i in range(1, min(6, len(coeffs)))]\n",
        "    return np.mean([np.mean(coeffs[i]) for i in valid_indices])\n",
        "\n",
        "\n",
        "def calculate_A_mean(coeffs):\n",
        "    return compute_mean(coeffs[0])\n",
        "\n",
        "def calculate_D_std(coeffs):\n",
        "    return np.mean([compute_std(coeffs[i]) for i in range(min(6, len(coeffs)))])\n",
        "\n",
        "def calculate_A_std(coeffs):\n",
        "    return compute_std(coeffs[0])\n",
        "\n",
        "\n",
        "def wavelet_feature_extraction(data, type_wav, sampling_frequency, nperseg):\n",
        "    coefficients = wavedec(data, type_wav, level=5)\n",
        "\n",
        "    total_energy = compute_total_energy(coefficients[0], coefficients[1:])\n",
        "    cD_Energy=calculate_D_Energy(coefficients[1:])\n",
        "    cA_Energy=compute_energy(coefficients[0])\n",
        "    cD_mean = calculate_D_mean(coefficients[1:])\n",
        "    cA_mean = calculate_A_mean(coefficients[0])\n",
        "    cD_std = calculate_D_std(coefficients[1:])\n",
        "    cA_std = calculate_A_std(coefficients[0])\n",
        "\n",
        "    return [\n",
        "        total_energy,\n",
        "        cD_Energy,\n",
        "        cA_Energy,\n",
        "        cD_mean,\n",
        "        cA_mean,\n",
        "        cD_std,\n",
        "        cA_std,\n",
        "    ]\n",
        "\n",
        "  #test"
      ],
      "metadata": {
        "id": "USYpboB4rzL9"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Frequency Domain coefficents"
      ],
      "metadata": {
        "id": "2NkvrDRAr5Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.signal\n",
        "import numpy as np\n",
        "\n",
        "def get_median_frequency(psd):\n",
        "    median_frequency = np.median(psd)\n",
        "\n",
        "    return median_frequency\n",
        "\n",
        "def get_edge_frequency(psd):\n",
        "    edge_frequency = np.where(psd >= psd.max() / 2)[0][0]\n",
        "\n",
        "    return edge_frequency\n",
        "\n",
        "def compute_power_spectral_density(data, sampling_frequency, nperseg=256):\n",
        "    _, psd = scipy.signal.welch(data, fs=sampling_frequency, nperseg=nperseg)\n",
        "    return psd\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = scipy.signal.butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = scipy.signal.lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "def compute_band_power(psd_result, freq_band_indices, fs, nperseg):\n",
        "    freq_band_power = np.sum(psd_result[freq_band_indices]) * fs / nperseg\n",
        "    return freq_band_power\n",
        "\n",
        "def compute_spectral_entropy(psd):\n",
        "    normalized_psd = psd / np.sum(psd)  # Normalize to obtain probabilities\n",
        "    spectral_entropy = -np.sum(normalized_psd * np.log2(normalized_psd))\n",
        "    return spectral_entropy\n",
        "\n",
        "def extract_frequency_domain_features(signal, sampling_frequency, nperseg=256):\n",
        "    # Apply Butterworth bandpass filters\n",
        "    delta_band_signal = butter_bandpass_filter(signal, 0.5, 4, sampling_frequency)\n",
        "    theta_band_signal = butter_bandpass_filter(signal, 4, 8, sampling_frequency)\n",
        "    alpha_band_signal = butter_bandpass_filter(signal, 8, 13, sampling_frequency)\n",
        "    beta_band_signal = butter_bandpass_filter(signal, 13, 30, sampling_frequency)\n",
        "    gamma_band_signal = butter_bandpass_filter(signal, 30, 40, sampling_frequency)\n",
        "\n",
        "    # Compute Power Spectral Density for each band\n",
        "    delta_psd = compute_power_spectral_density(delta_band_signal, sampling_frequency, nperseg=nperseg)\n",
        "    theta_psd = compute_power_spectral_density(theta_band_signal, sampling_frequency, nperseg=nperseg)\n",
        "    alpha_psd = compute_power_spectral_density(alpha_band_signal, sampling_frequency, nperseg=nperseg)\n",
        "    beta_psd = compute_power_spectral_density(beta_band_signal, sampling_frequency, nperseg=nperseg)\n",
        "    gamma_psd = compute_power_spectral_density(gamma_band_signal, sampling_frequency, nperseg=nperseg)\n",
        "\n",
        "    # Compute Band Power for each frequency band\n",
        "    freq_band_indices = [range(int(nperseg * band[0] / sampling_frequency), int(nperseg * band[1] / sampling_frequency)) for band in [(0.5, 4), (4, 8), (8, 13), (13, 30), (30, 40)]]\n",
        "\n",
        "    delta_band_power = compute_band_power(delta_psd, freq_band_indices[0], sampling_frequency, nperseg)\n",
        "    theta_band_power = compute_band_power(theta_psd, freq_band_indices[1], sampling_frequency, nperseg)\n",
        "    alpha_band_power = compute_band_power(alpha_psd, freq_band_indices[2], sampling_frequency, nperseg)\n",
        "    beta_band_power = compute_band_power(beta_psd, freq_band_indices[3], sampling_frequency, nperseg)\n",
        "    gamma_band_power = compute_band_power(gamma_psd, freq_band_indices[4], sampling_frequency, nperseg)\n",
        "\n",
        "    spectral_entropy_result = compute_spectral_entropy(np.concatenate([delta_psd, theta_psd, alpha_psd, beta_psd, gamma_psd]))\n",
        "    # Compute the power spectral density (PSD)\n",
        "    psd, _ = scipy.signal.welch(signal, fs=sampling_frequency, nperseg=nperseg)\n",
        "\n",
        "    return [\n",
        "        delta_band_power,\n",
        "        theta_band_power,\n",
        "        alpha_band_power,\n",
        "        beta_band_power,\n",
        "        gamma_band_power,\n",
        "        spectral_entropy_result,\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "nr1UFcvMruIA"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Time Domain coefficents"
      ],
      "metadata": {
        "id": "rezQXOYbsBCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.fft import fft\n",
        "import pywt\n",
        "import os\n",
        "from scipy.stats import entropy, skew, kurtosis\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = scipy.signal.butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "def compute_standard_deviation(data):\n",
        "    return np.std(data)\n",
        "\n",
        "def compute_skewness(data):\n",
        "    return skew(data)\n",
        "\n",
        "def compute_kurtosis(data):\n",
        "    return kurtosis(data)\n",
        "\n",
        "def compute_median(data):\n",
        "    return np.median(data)\n",
        "\n",
        "def compute_band_power_time(data, sampling_frequency, nperseg):\n",
        "    _, power_density = welch(data, fs=sampling_frequency, nperseg=nperseg)\n",
        "    return np.mean(power_density)\n",
        "def peak_to_peak_voltage(data):\n",
        "    return np.ptp(data)\n",
        "\n",
        "def total_signal_area(data):\n",
        "    return np.sum(np.abs(data))\n",
        "\n",
        "def decorrelation_time(data):\n",
        "    autocorrelation = np.correlate(data, data, mode='full')\n",
        "    zero_crossings = np.where(np.diff(np.sign(autocorrelation)))[0]\n",
        "\n",
        "    if len(zero_crossings) > 0:\n",
        "        first_zero_crossing = zero_crossings[0]\n",
        "        time_points = np.arange(len(autocorrelation))\n",
        "        decorrelation_time = time_points[first_zero_crossing]\n",
        "        return decorrelation_time\n",
        "    else:\n",
        "        return -1\n",
        "def extract_time_domain_features(raw_data,sampling_frequency, nperseg):\n",
        "    data=butter_bandpass_filter(raw_data, 0.5, 40, sampling_frequency)\n",
        "    features = [\n",
        "        compute_standard_deviation(data),\n",
        "        compute_skewness(data),\n",
        "        compute_kurtosis(data),\n",
        "        compute_median(data),\n",
        "        compute_band_power_time(data, sampling_frequency, nperseg),\n",
        "        peak_to_peak_voltage(data),\n",
        "        total_signal_area(data),\n",
        "        decorrelation_time(data)\n",
        "    ]\n",
        "    return features"
      ],
      "metadata": {
        "id": "LrNgQFT2sDby"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction"
      ],
      "metadata": {
        "id": "-Y6fZKqPsIzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "from scipy.fft import fft\n",
        "import pywt\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def calculate_mean(segments):\n",
        "    num_segments,num_channels, num_features = np.array(segments).shape\n",
        "    mean_features=[]\n",
        "    for channel in range(num_channels):\n",
        "      feature_array=[]\n",
        "      feature_array_total=[]\n",
        "      for segment in range(num_segments):\n",
        "        feature_array= segments[segment][channel]\n",
        "        feature_array_total.append(feature_array)\n",
        "      mean_features.append(np.mean(feature_array_total))\n",
        "    return (mean_features)\n",
        "\n",
        "def extract_features(segment, seizure):\n",
        "    num_channels, num_time_points = segment.shape\n",
        "    all_features = []\n",
        "\n",
        "    for channel_index, channel_data in enumerate(segment):\n",
        "        extracted_features = []\n",
        "        wavelet_name = 'db4'\n",
        "        extracted_features.extend(wavelet_feature_extraction(channel_data, wavelet_name, 256, 256))\n",
        "        extracted_features.extend(extract_time_domain_features(channel_data, 256, 256))\n",
        "        extracted_features.extend(extract_frequency_domain_features(channel_data, 256))\n",
        "        if seizure:\n",
        "          extracted_features.extend([channel_index, 1])\n",
        "        else:\n",
        "          extracted_features.extend([channel_index, 0])\n",
        "\n",
        "        all_features.append(extracted_features)\n",
        "\n",
        "    return np.array(all_features)\n",
        "\n",
        "def extract_features_without_segments(data, time_window_duration = 60, seizure = False):\n",
        "    num_channels, num_data_points = data.shape\n",
        "    data_per_segment = time_window_duration * 256\n",
        "\n",
        "    num_segments = num_data_points // data_per_segment\n",
        "    all_features = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        print('segment', i)\n",
        "        features = extract_features(data[:, i * data_per_segment: (i + 1) * data_per_segment],seizure)\n",
        "        all_features.append(features)\n",
        "    featuer_log.info(f\"äll featuers before averaging: {np.array(all_features).shape}\")\n",
        "\n",
        "    featuer_log.info(f\"äll featuers after averaging: {np.array(calculate_mean(all_features)).shape}\")\n",
        "    return calculate_mean(all_features)\n",
        "\n"
      ],
      "metadata": {
        "id": "3ojz6ayXsLK4"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_and_process_files(folder_path, time_window_duration = 60):\n",
        "#     file_list = [f for f in os.listdir(folder_path) if f.endswith('.npy')]\n",
        "\n",
        "#     df=pd.DataFrame(columns=feature_names)\n",
        "\n",
        "#     for file_name in file_list:\n",
        "#         file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "#         data = np.load(file_path)\n",
        "#         features = extract_features_without_segments(data, time_window_duration,feature_names)\n",
        "#         df = pd.concat([df, features], ignore_index=True)\n",
        "\n",
        "#         print('file: ',file_name)\n",
        "#         del data\n",
        "\n",
        "#     return df"
      ],
      "metadata": {
        "id": "Qimht3wjsPgL"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "7Uvksy_WsUQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_log = create_log()"
      ],
      "metadata": {
        "id": "mOIxAEZ4g6k-"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class EEGData:\n",
        "    def __init__(self, file_name, file_start_time, file_end_time, num_seizures, seizure_times=[]):\n",
        "        self.file_name = file_name\n",
        "        self.file_start_time = file_start_time\n",
        "        self.file_end_time = file_end_time\n",
        "        self.num_seizures = num_seizures\n",
        "        self.seizure_times = seizure_times\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"EEGData(File Name: {self.file_name}, \"\n",
        "                f\"File Start Time: {self.file_start_time}, \"\n",
        "                f\"File End Time: {self.file_end_time}, \"\n",
        "                f\"Number of Seizures: {self.num_seizures}, \"\n",
        "                f\"Number of Seizures: {self.seizure_times})\")"
      ],
      "metadata": {
        "id": "zRQ-b5X9t2fI"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_eeg_data(file_path):\n",
        "    eeg_data_objects = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    current_file_data = {}\n",
        "    num_seizures = 0\n",
        "    line_index = 0\n",
        "    while line_index<len(lines):\n",
        "      line = lines[line_index]\n",
        "      if line.startswith('File Name:'):\n",
        "          if current_file_data:\n",
        "              # Create EEGData object from the current_file_data\n",
        "              eeg_data = EEGData(**current_file_data)\n",
        "              eeg_data_objects.append(eeg_data)\n",
        "\n",
        "              current_file_data = {}\n",
        "          current_file_data['file_name'] = line.split(': ')[1].strip()\n",
        "      elif line.startswith('File Start Time:'):\n",
        "          current_file_data['file_start_time'] = line.split(': ')[1].strip()\n",
        "      elif line.startswith('File End Time:'):\n",
        "          current_file_data['file_end_time'] = line.split(': ')[1].strip()\n",
        "      elif line.startswith('Number of Seizures in File:'):\n",
        "          current_file_data['num_seizures'] = int(line.split(': ')[1].strip())\n",
        "          num_seizures = current_file_data['num_seizures']\n",
        "\n",
        "          seizure_times = []\n",
        "\n",
        "          if num_seizures > 1:\n",
        "\n",
        "            for x in range(num_seizures):\n",
        "              line_index += 1\n",
        "              start = int(lines[line_index].split(\": \")[1].strip().split(\" \")[0].strip())\n",
        "              line_index += 1\n",
        "              end = int(lines[line_index].split(\": \")[1].strip().split(\" \")[0].strip())\n",
        "              seizure = (start,end)\n",
        "              seizure_times.append(seizure)\n",
        "\n",
        "          elif num_seizures  == 1:\n",
        "            line_index += 1\n",
        "            start = int(lines[line_index].split(\": \")[1].split(\" \")[0].strip())\n",
        "            line_index += 1\n",
        "            end = int(lines[line_index].split(\": \")[1].split(\" \")[0].strip())\n",
        "            seizure_times.append((start,end))\n",
        "\n",
        "          current_file_data['seizure_times'] = seizure_times\n",
        "\n",
        "          if 'file_name' in current_file_data:\n",
        "              eeg_data = EEGData(**current_file_data)\n",
        "              eeg_data_objects.append(eeg_data)\n",
        "              current_file_data = {}\n",
        "      line_index += 1\n",
        "    return eeg_data_objects\n"
      ],
      "metadata": {
        "id": "lwTzw7Y2H1MN"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import mne\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def load_data_from_file(patient_id,file_name):\n",
        "  file = f\"/content/drive/MyDrive/EEG-Projects/CHB-MIT/{patient_id}/{file_name}\"\n",
        "  data = mne.io.read_raw_edf(file)\n",
        "  preprocessing_log.info(f\"loaded EDF file at {file_name} with patient id : {patient_id}\")\n",
        "  return data"
      ],
      "metadata": {
        "id": "6BRBcnlcunpg"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def clean_channel_data(data_file):\n",
        "  data = data_file.get_data()\n",
        "  preprocessing_log.info(f\"data shape before cleaning: {data.shape}\")\n",
        "\n",
        "  modified_data = []\n",
        "  channel_num, data_num = data.shape\n",
        "  if channel_num > 23:\n",
        "    additional_channel = True\n",
        "    for channel_index in range(len(data)):\n",
        "      element = data[channel_index][random.randint(0,data_num-1)]\n",
        "\n",
        "      if element != -1e-06:\n",
        "        modified_data.append(data[channel_index])\n",
        "      else:\n",
        "        preprocessing_log.info(f\"removed channel index {channel_index}\")\n",
        "\n",
        "    if len(modified_data) > 23:\n",
        "      modified_data.pop(-1)\n",
        "      preprocessing_log.info(f\"removed ECG channel\")\n",
        "\n",
        "    new_data = np.array(modified_data)\n",
        "    preprocessing_log.info(f\"data shape changed from {data.shape} => {new_data.shape}\")\n",
        "    del modified_data,data\n",
        "    gc.collect()\n",
        "    return new_data\n",
        "\n",
        "  preprocessing_log.info(\"data is clean\")\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "NTNOPXeJiGez"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_non_sezizer_segments(patient_id,eeg_data_objects, segment_length = 600, time_gap =300):\n",
        "  count = 0\n",
        "  for i in range(len(eeg_data_objects)):\n",
        "    if (int(eeg_data_objects[i].num_seizures) == 0) and i-4 >= 0 and i+3 < len(eeg_data_objects):\n",
        "      preprocessing_log.info(f\"[+] non-seizure: {eeg_data_objects[i]}\")\n",
        "      flag = True\n",
        "      index = i-1\n",
        "      for j in range(4):\n",
        "        if eeg_data_objects[index].num_seizures != 0:\n",
        "          flag = False\n",
        "        index-=1\n",
        "      index = i\n",
        "      for k in range(3):\n",
        "        if eeg_data_objects[index].num_seizures != 0:\n",
        "          flag = False\n",
        "        index+=1\n",
        "\n",
        "      if flag:\n",
        "        preprocessing_log.info(f\"{eeg_data_objects[i]}, {eeg_data_objects[i-1]}\")\n",
        "        # print(eeg_data_objects[i],eeg_data_objects[i-1])\n",
        "        obj1 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i].file_name))\n",
        "\n",
        "        obj2 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i-1].file_name))\n",
        "\n",
        "        f1_no = eeg_data_objects[i].file_name.split('_')[1].split('.')[0]\n",
        "        f2_no = eeg_data_objects[i-1].file_name.split('_')[1].split('.')[0]\n",
        "\n",
        "        conect_data = np.concatenate((obj1, obj2), axis=1)[:segment_length*256]\n",
        "        preprocessing_log.info(f\"conect data shape non-seizure: {conect_data.shape}\")\n",
        "        preprocessing_log.info(f\"time range non-sezuer: {segment_length/3600}\")\n",
        "\n",
        "\n",
        "        extracted_featuers = extract_features_without_segments(conect_data)\n",
        "        preprocessing_log.info(f\"extracted featuer shape: {extracted_featuers.shape}\")\n",
        "        np.save(f\"/content/drive/MyDrive/EEG-Projects/CHB-MIT-Extracted-Featuers/non-seizuer-cases/{patient_id}-{f1_no}-{f2_no}.npy\",extracted_featuers)\n",
        "        del obj1\n",
        "        del obj2\n",
        "        del conect_data\n",
        "        gc.collect()\n",
        "    elif (int(eeg_data_objects[i].num_seizures) > 0) and (i-2 >= 0):\n",
        "      preprocessing_log.info(f\"[+] seizure: {eeg_data_objects[i]}\")\n",
        "      f1_no = eeg_data_objects[i].file_name.split('_')[1].split('.')[0]\n",
        "      f2_no = eeg_data_objects[i-1].file_name.split('_')[1].split('.')[0]\n",
        "      flag = True\n",
        "\n",
        "\n",
        "      obj1 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i].file_name))\n",
        "      obj2 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i-1].file_name))\n",
        "      obj3 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i-2].file_name))\n",
        "      time_correction = len(obj2[0])/256 + len(obj3[0])/256\n",
        "      shape_flag = False\n",
        "\n",
        "      if obj1.shape[0] == obj2.shape[0] == obj3.shape[0]:\n",
        "\n",
        "        shape_flag = True\n",
        "\n",
        "      obj4 = None\n",
        "      if i-3 >= 0:\n",
        "        obj4 = clean_channel_data(load_data_from_file(patient_id,eeg_data_objects[i-3].file_name))\n",
        "        if obj1.shape[0] != obj4.shape[0] and shape_flag == True:\n",
        "          shape_flag = False\n",
        "\n",
        "        time_correction += len(obj4[0])/256\n",
        "\n",
        "      preprocessing_log.info(f\"data shapes: {obj1.shape} {obj2.shape} {obj3.shape}\")\n",
        "\n",
        "      if shape_flag == False:\n",
        "        preprocessing_log.info(\"Shapes doesn't match!\")\n",
        "        continue\n",
        "\n",
        "      preprocessing_log.info(f\"time correction: {time_correction}\")\n",
        "\n",
        "      timeline = []\n",
        "      if np.all(obj4 != None):\n",
        "        timeline = np.concatenate((obj4,obj3,obj2,obj1),axis=1)\n",
        "      else:\n",
        "        timeline = np.concatenate((obj3,obj2,obj1),axis=1)\n",
        "\n",
        "      preprocessing_log.info(timeline.shape)\n",
        "\n",
        "      s_count = 0\n",
        "      for s in eeg_data_objects[i].seizure_times:\n",
        "        seizure_data = []\n",
        "\n",
        "        start_time = s[0] + time_correction\n",
        "        end_time = s[1] + time_correction\n",
        "        preprocessing_log.info(f\"capture margin: {start_time} - {end_time}\")\n",
        "\n",
        "        end_margin = start_time - time_gap\n",
        "        start_margin = end_margin - segment_length\n",
        "\n",
        "        start_data_index = int(start_margin * 256)\n",
        "        end_data_index = int(end_margin * 256)\n",
        "        n_channels = timeline.shape[0]\n",
        "        for x in range(n_channels):\n",
        "\n",
        "          channel_data = timeline[x][start_data_index:end_data_index]\n",
        "          seizure_data.append(channel_data)\n",
        "        np_seizure = np.array(seizure_data,dtype=np.float32)\n",
        "\n",
        "        preprocessing_log.info(f\"pre-ictal data shape: {np_seizure.shape}\")\n",
        "        extracted_featuers = extract_features_without_segments(np_seizure, seizure=True)\n",
        "        np.save(f\"/content/drive/MyDrive/EEG-Projects/CHB-MIT-Extracted-Featuers/seizuer-cases/{patient_id}-{f1_no}-{f2_no}.npy\",extracted_featuers)\n",
        "        preprocessing_log.info(f\"extracted featuer shape: {np.array(extracted_featuers).shape}\")\n",
        "        s_count+=1\n",
        "      preprocessing_log.info(f\"time range sezuer: {segment_length/3600}\")\n",
        "      preprocessing_log.info(f\"number of sezuers: {s_count}\")\n",
        "\n",
        "      preprocessing_log.info(f\"data length: {len(seizure_data)}\")\n",
        "      del obj1,obj2,obj3,obj4,seizure_data\n",
        "      gc.collect()\n",
        "    count+=1"
      ],
      "metadata": {
        "id": "9p96sIMp2qV3"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_two_hour_segments(patient_id):\n",
        "  eeg_data_objects = parse_eeg_data(f'/content/drive/MyDrive/EEG-Projects/CHB-MIT/{patient_id}/{patient_id}-summary.txt')\n",
        "  create_non_sezizer_segments(patient_id,eeg_data_objects)\n",
        "  del eeg_data_objects\n",
        "  gc.collect"
      ],
      "metadata": {
        "id": "LhXZmqJQB06g"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gowpbEqPR3TB",
        "outputId": "9b87222c-8fa6-46f3-f792-1dcb0c78e959"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "161"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm \"preprocess-pipeline.log\"\n",
        "# create_log()"
      ],
      "metadata": {
        "id": "pyiIfNtZTuie"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# patient_id = \"chb13\"\n",
        "# load_two_hour_segments(patient_id)"
      ],
      "metadata": {
        "id": "GuRC2ur9RxWj"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(23):\n",
        "  patient_id = f\"chb{i+1:02d}\"\n",
        "  load_two_hour_segments(patient_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybTIc8q4BOU7",
        "outputId": "2b60ef01-c71b-4009-9b81-2da63166cbc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:preprocess-pipeline:[+] seizure: EEGData(File Name: chb01_03.edf, File Start Time: 13:43:04, File End Time: 14:43:04, Number of Seizures: 1, Number of Seizures: [(2996, 3036)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/drive/MyDrive/EEG-Projects/CHB-MIT/chb01/chb01_03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-5c87bc86bad2>:9: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  data = mne.io.read_raw_edf(file)\n",
            "INFO:preprocess-pipeline:loaded EDF file at chb01_03.edf with patient id : chb01\n",
            "INFO:preprocess-pipeline:data shape before cleaning: (23, 921600)\n",
            "INFO:preprocess-pipeline:data is clean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/drive/MyDrive/EEG-Projects/CHB-MIT/chb01/chb01_02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-5c87bc86bad2>:9: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  data = mne.io.read_raw_edf(file)\n",
            "INFO:preprocess-pipeline:loaded EDF file at chb01_02.edf with patient id : chb01\n",
            "INFO:preprocess-pipeline:data shape before cleaning: (23, 921600)\n",
            "INFO:preprocess-pipeline:data is clean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/drive/MyDrive/EEG-Projects/CHB-MIT/chb01/chb01_01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-5c87bc86bad2>:9: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  data = mne.io.read_raw_edf(file)\n",
            "INFO:preprocess-pipeline:loaded EDF file at chb01_01.edf with patient id : chb01\n",
            "INFO:preprocess-pipeline:data shape before cleaning: (23, 921600)\n",
            "INFO:preprocess-pipeline:data is clean\n",
            "INFO:preprocess-pipeline:data shapes: (23, 921600) (23, 921600) (23, 921600)\n",
            "INFO:preprocess-pipeline:time correction: 7200.0\n",
            "INFO:preprocess-pipeline:(23, 2764800)\n",
            "INFO:preprocess-pipeline:capture margin: 10196.0 - 10236.0\n",
            "INFO:preprocess-pipeline:pre-ictal data shape: (23, 153600)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "segment 0\n",
            "segment 1\n",
            "segment 2\n",
            "segment 3\n",
            "segment 4\n",
            "segment 5\n",
            "segment 6\n",
            "segment 7\n",
            "segment 8\n",
            "segment 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:featuer-extraction:äll featuers before averaging: (10, 23, 23)\n",
            "INFO:featuer-extraction:äll featuers after averaging: (23,)\n",
            "INFO:preprocess-pipeline:extracted featuer shape: (23,)\n",
            "INFO:preprocess-pipeline:time range sezuer: 0.16666666666666666\n",
            "INFO:preprocess-pipeline:number of sezuers: 1\n",
            "INFO:preprocess-pipeline:data length: 23\n",
            "INFO:preprocess-pipeline:[+] seizure: EEGData(File Name: chb01_04.edf, File Start Time: 14:43:12, File End Time: 15:43:12, Number of Seizures: 1, Number of Seizures: [(1467, 1494)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/drive/MyDrive/EEG-Projects/CHB-MIT/chb01/chb01_04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-5c87bc86bad2>:9: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  data = mne.io.read_raw_edf(file)\n",
            "INFO:preprocess-pipeline:loaded EDF file at chb01_04.edf with patient id : chb01\n",
            "INFO:preprocess-pipeline:data shape before cleaning: (23, 921600)\n",
            "INFO:preprocess-pipeline:data is clean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/drive/MyDrive/EEG-Projects/CHB-MIT/chb01/chb01_03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-5c87bc86bad2>:9: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  data = mne.io.read_raw_edf(file)\n",
            "INFO:preprocess-pipeline:loaded EDF file at chb01_03.edf with patient id : chb01\n",
            "INFO:preprocess-pipeline:data shape before cleaning: (23, 921600)\n",
            "INFO:preprocess-pipeline:data is clean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/drive/MyDrive/EEG-Projects/CHB-MIT/chb01/chb01_02.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-5c87bc86bad2>:9: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  data = mne.io.read_raw_edf(file)\n",
            "INFO:preprocess-pipeline:loaded EDF file at chb01_02.edf with patient id : chb01\n",
            "INFO:preprocess-pipeline:data shape before cleaning: (23, 921600)\n",
            "INFO:preprocess-pipeline:data is clean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/drive/MyDrive/EEG-Projects/CHB-MIT/chb01/chb01_01.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-5c87bc86bad2>:9: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  data = mne.io.read_raw_edf(file)\n",
            "INFO:preprocess-pipeline:loaded EDF file at chb01_01.edf with patient id : chb01\n",
            "INFO:preprocess-pipeline:data shape before cleaning: (23, 921600)\n",
            "INFO:preprocess-pipeline:data is clean\n",
            "INFO:preprocess-pipeline:data shapes: (23, 921600) (23, 921600) (23, 921600)\n",
            "INFO:preprocess-pipeline:time correction: 10800.0\n",
            "INFO:preprocess-pipeline:(23, 3686400)\n",
            "INFO:preprocess-pipeline:capture margin: 12267.0 - 12294.0\n",
            "INFO:preprocess-pipeline:pre-ictal data shape: (23, 153600)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "segment 0\n",
            "segment 1\n",
            "segment 2\n",
            "segment 3\n",
            "segment 4\n",
            "segment 5\n",
            "segment 6\n",
            "segment 7\n",
            "segment 8\n",
            "segment 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:featuer-extraction:äll featuers before averaging: (10, 23, 23)\n",
            "INFO:featuer-extraction:äll featuers after averaging: (23,)\n",
            "INFO:preprocess-pipeline:extracted featuer shape: (23,)\n",
            "INFO:preprocess-pipeline:time range sezuer: 0.16666666666666666\n",
            "INFO:preprocess-pipeline:number of sezuers: 1\n",
            "INFO:preprocess-pipeline:data length: 23\n",
            "INFO:preprocess-pipeline:[+] non-seizure: EEGData(File Name: chb01_05.edf, File Start Time: 15:43:19, File End Time: 16:43:19, Number of Seizures: 0, Number of Seizures: [])\n",
            "INFO:preprocess-pipeline:[+] non-seizure: EEGData(File Name: chb01_06.edf, File Start Time: 16:43:26, File End Time: 17:43:26, Number of Seizures: 0, Number of Seizures: [])\n",
            "INFO:preprocess-pipeline:[+] non-seizure: EEGData(File Name: chb01_07.edf, File Start Time: 17:43:33, File End Time: 18:43:33, Number of Seizures: 0, Number of Seizures: [])\n",
            "INFO:preprocess-pipeline:[+] non-seizure: EEGData(File Name: chb01_08.edf, File Start Time: 18:43:40, File End Time: 19:43:40, Number of Seizures: 0, Number of Seizures: [])\n",
            "INFO:preprocess-pipeline:[+] non-seizure: EEGData(File Name: chb01_09.edf, File Start Time: 19:43:56, File End Time: 20:43:56, Number of Seizures: 0, Number of Seizures: [])\n",
            "INFO:preprocess-pipeline:EEGData(File Name: chb01_09.edf, File Start Time: 19:43:56, File End Time: 20:43:56, Number of Seizures: 0, Number of Seizures: []), EEGData(File Name: chb01_08.edf, File Start Time: 18:43:40, File End Time: 19:43:40, Number of Seizures: 0, Number of Seizures: [])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/drive/MyDrive/EEG-Projects/CHB-MIT/chb01/chb01_09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-5c87bc86bad2>:9: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  data = mne.io.read_raw_edf(file)\n",
            "INFO:preprocess-pipeline:loaded EDF file at chb01_09.edf with patient id : chb01\n",
            "INFO:preprocess-pipeline:data shape before cleaning: (23, 921600)\n",
            "INFO:preprocess-pipeline:data is clean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/drive/MyDrive/EEG-Projects/CHB-MIT/chb01/chb01_08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-5c87bc86bad2>:9: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  data = mne.io.read_raw_edf(file)\n",
            "INFO:preprocess-pipeline:loaded EDF file at chb01_08.edf with patient id : chb01\n",
            "INFO:preprocess-pipeline:data shape before cleaning: (23, 921600)\n",
            "INFO:preprocess-pipeline:data is clean\n",
            "INFO:preprocess-pipeline:conect data shape non-seizure: (23, 1843200)\n",
            "INFO:preprocess-pipeline:time range non-sezuer: 0.16666666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "segment 0\n",
            "segment 1\n",
            "segment 2\n",
            "segment 3\n",
            "segment 4\n",
            "segment 5\n",
            "segment 6\n",
            "segment 7\n",
            "segment 8\n",
            "segment 9\n",
            "segment 10\n",
            "segment 11\n",
            "segment 12\n",
            "segment 13\n",
            "segment 14\n",
            "segment 15\n",
            "segment 16\n",
            "segment 17\n",
            "segment 18\n",
            "segment 19\n",
            "segment 20\n",
            "segment 21\n",
            "segment 22\n",
            "segment 23\n",
            "segment 24\n",
            "segment 25\n",
            "segment 26\n",
            "segment 27\n",
            "segment 28\n",
            "segment 29\n"
          ]
        }
      ]
    }
  ]
}